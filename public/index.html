
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Technoblogic</title>
  <meta name="author" content="Jeff Malnick">

  
  <meta name="description" content="The Data Center Operating System (DCOS) is a distributed, highly available task scheduler built by Mesosphere. It uses a number of open and close &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://technoblogic.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Technoblogic" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href='https://fonts.googleapis.com/css?family=Noto+Serif:400,700' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Technoblogic</a></h1>
  
    <h2>Musings on DevOps</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="technoblogic.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/blog/archives">All Posts</a></li>
  <li><a href="/blog/resume">Resume</a></li>
  <li><a href="/blog/talks">Talks/Public Venues</a></li>
  <li><a href="https://github.com/malnick">Github</a></li>
  <li><a href="https://www.flickr.com/photos/129457394@N03/">Flickr</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/31/building-an-installer-for-the-data-center-operating-system/">Building an Installer for the Data Center Operating System</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-31T08:51:38-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>31</span><span class='date-suffix'>st</span>, <span class='date-year'>2016</span></span> <span class='time'>8:51 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The Data Center Operating System (DCOS) is a distributed, highly available task scheduler built by <a href="http://mesosphere.io">Mesosphere</a>. It uses a number of open and close source projects to make running and administering Apache Mesos as seemless and simple as possible. The DCOS runs at scale (we have customers running production deployments of 50,000 nodes), across thousands of machines. It&rsquo;s primary goal is to abstract away the mundane and technically challenging process of deploying highly available applications. The DCOS consists of masters and agents. In a typical production deployment you have 3 to 5 masters and &lsquo;n&rsquo; number of agents that comprise the core resources of your cluster.</p>

<h2>Installation Challenge</h2>

<p>Installation of the DCOS has always been a tricky endeavor. Each cluster has site-specific customizations which must be translated into configuration files for various pieces of the DCOS ecosystem. These configuration files need to be compiled into a shippable package and those packages need to be installed on tens of thousands of hosts.</p>

<p>This configuration generation process differs based on locality: is the deployment in AWS or another cloud platform where we might not know master IP addresses before deployment? Is the deployment behind a VRRP or other master-host load balancer such as an ELB? Is the customer using zookeeper, S3 or a shared file system for <a href="https://github.com/Netflix/exhibitor">Exhibitor</a>&rsquo;s bootstrapping process?</p>

<p>The technical challenges of installation don&rsquo;t stop with configuration generation either. Beyond that, simply ensuring that DCOS is shipped and properly configured on each host poses even more obsticles. We can&rsquo;t ship the DCOS as an RPM, Yum or Apt package as this would cause chaos during upgrades. Not only do we have a concept of upgrading the underlying DCOS software but we also have a concept of upgrading the frameworks, stateless and stateful, which run on top of it.</p>

<p>For lack of a better meme,</p>

<p>  &ldquo;One does not simply upgrade the Data Center Operating System&rdquo;.</p>

<p>When you install the DCOS, you need to install a specific role on each host depending on if that host is a master, a public agent or a private agent, or just simply an agent.</p>

<p>Sure this whole thing would be simple with Ansible, Puppet or Chef. But you can&rsquo;t ship enterprise software and pigeon hole your paying customers into using one of these systems over the other. Furthermore, this is the DCOS - it should be installable without involving complicated configuration management systems. We wanted to build a tool that you could run, access in a UI and deploy a cluster with minimal end-user thinking.</p>

<h2>In the Beginning</h2>

<p>The first version of the DCOS installer consisted of a utility that read in a JSON configuration file which declared site-specific customizations, and generated a bootstrap and associated packages. However, the end-user was left to develop a way to ship those components or make them available to our install script, which itself had to be shipped around to hosts and somehow executed.</p>

<p>Furthermore, because of the way we process this configuration file to generate the site-specific configuration files we required that all things in this JSON file were strings. For example, even though we processed an array of IPv4 addresses for the <code>resolvers</code> setting, you had to enter in that array as a string:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="s2">&quot;resolvers&quot;</span><span class="err">:</span> <span class="s2">&quot;[\&quot;8.8.8.8\&quot;, \&quot;8.8.4.4\&quot;]&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Obviously this wasn&rsquo;t an ideal end-user experience. It was even harder to get the wording right in the docs so people understood what we meant.</p>

<p>The first 4 versions of the installer were designed around building the configuration for the DCOS. The artifacts from running <code>dcos_generate_config.sh</code> would output the entire cluster cluster configuration as packages and a bootstrap tar ball plus a handy <code>install_dcos.sh</code> which pointed at the value for the <code>bootstrap_url</code> parameter in your config.json. You could ship this script to each host in your infrastructure, and run <code>./install_dcos.sh $ROLE</code> (where $ROLE is master, slave or slave_public) and it would download these artifacts and install the DCOS.</p>

<p>This was slick, but still required the end-user do a lot of manual work. She had to setup a nginx or other web server to serve the artifacts from the host in the <code>bootstrap_url</code>. She had to manually move the install script to each host and run run it. She also, per host, had to manually run the preflight.</p>

<p>It became apparent that we needed a way to automate the entire installation process across the cluster. Where in a previous life I could reach for Puppet, Chef or Ansible to do this distributed dirty work, we could not pigeon hole customers into deploying one of these systems. We had to stick to system utilities and embody a &ldquo;leave no trace&rdquo; policy - the only artifact the installer should leave is a working DCOS master or agent installation on each host.</p>

<p>Furthermore, our automated installer should be user-friendly, easy to understand and run those preflight and postflight checks in a single place (like a web UI!).</p>

<h2>SSH Library Design Concept</h2>

<p>Mesosphere is a Python shop, being able to leverage an existing library to do the SSHing would be fantastic. We vetted the following libraries:</p>

<ol>
<li><a href="https://github.com/ansible/ansible">Ansible SSH Library</a></li>
<li><a href="https://docs.saltstack.com/en/latest/topics/ssh/">Salt SSH Library</a></li>
<li><a href="http://www.paramiko.org/">Paramiko</a></li>
<li><a href="https://pypi.python.org/pypi/parallel-ssh">Parallel SSH</a></li>
<li><a href="http://asyncssh.readthedocs.org/en/latest/">Async SSH</a></li>
<li>Subprocess (shelling out to SSH)</li>
</ol>


<p>Unfortunately, every library we tried we were unable to implement. The library was either not compatible with Python 3x or had licensing restrictions. This left us with concurrent subprocess calls to the SSH executable. This wasn&rsquo;t something that we were particularly fond of, because if you&rsquo;ve ever seen how much code it takes to make this a viable option (just look at <a href="https://github.com/ansible/ansible/blob/stable-2.0.0.1/lib/ansible/executor/task_executor.py#L49">Ansible&rsquo;s SSH executor class</a> you can understand it&rsquo;s not trivial.</p>

<p>Also, our final product would be a web-based GUI with a CLI utility. The library we chose must be compatible with asyncio, which will be the web framework of the final HTTP API.</p>

<h2>Development Schedule</h2>

<p>We had two 6 week release cycles to come out with this installer. However, the final 6 week release cycle had 2 weeks of holiday at the end of December, so really we designed, implemented and depoyed this entire application in a total of 10 weeks. That&rsquo;s, 10 weeks to build a UI with a highly concurrent, asynchronous SSH library, configuration generation system which successfully preflights and postflights the cluster as well as install the DCOS - a highly available fault tolerant distributed scheduler consisting of 82 executable pieces of software (<code>ls /opt/mesosphere/bin | wc -l</code>).</p>

<p>No big deal.</p>

<h2>CM.5 - SSH Deployment MVP</h2>

<p>For our first release cycle, CM.5, we aimed to ship a minimally viable product for installing the DCOS over SSH. No user interface yet, just a CLI utility for installing.</p>

<p>The CLI interface consisted of a few arguments to generate configuration, preflight hosts, install to hosts, postflight the hosts, and if required, uninstall the hosts:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>optional arguments:
</span><span class='line'>  -h, --help            show this <span class="nb">help </span>message and <span class="nb">exit</span>
</span><span class='line'>  -l, --log-level       Verbose log output <span class="o">(</span>DEBUG<span class="o">)</span>.
</span><span class='line'>  --genconf             Execute the configuration generation <span class="o">(</span>genconf<span class="o">)</span>.
</span><span class='line'>  --preflight           Execute the preflight checks on a series of nodes.
</span><span class='line'>  --deploy              Execute a deploy.
</span><span class='line'>  --postflight          Execute postflight checks on a series of nodes.
</span><span class='line'>  --uninstall           Execute uninstall on target hosts.
</span></code></pre></td></tr></table></div></figure>


<h3>YAML Configuration File</h3>

<p>JSON is great as an interchange format for shipping data between machines. But humans are bad at remembering to double versus single quote, get all the commas (except that last line!), etc. We decided to move to a more user-friendly configuration file format with YAML.</p>

<h3>Concurrent SSH Library</h3>

<p>CM.5 would be our MVP for our SSH library. The goal was to build a concurrent SSH library that deployed the DCOS. We would re-use this code base in CM.6 for the UI installer.</p>

<h3>Inital Problems</h3>

<p>We built out the CLI and of course ran into all the wonders of problems one runs into deploying things over SSH:</p>

<h5>requiretty</h5>

<p>By default, almost every Linux distro ships with <code>/etc/sudoers</code> set to <code>requiretty</code> to execute sudo. To fix this, we added a PTY directly to our SSH subprocess and execute SSH with <code>-tt</code>.</p>

<h5>SSH Keys</h5>

<p>The verdict is still out on this, but we had a lot of internal discussions about how customers will react to giving us the SSH keys to their cluster to deploy this system.</p>

<p>In order to alleviate this, we designed our CLI to be the &ldquo;advanced&rdquo; mode. Users can still deploy the DCOS manually but supplying the correct <code>bootstrap_url`` to the config.yaml file. They can opt to run the installer with</code>&ndash;genconf``` only, and then manually ship the configuration artifacts as we have in the past.</p>

<h5>Paths to Things</h5>

<p>Our installer runs in a docker container. We mount a volume on the host machine called &ldquo;genconf/&rdquo; which contains all the configuration artifacts. However, when we shipped CM.5 we also required users put things like <code>ssh_key</code> in there. This path was visable in the config.yaml file as <code>ssh_key_path: /genconf/ssh_key</code>. But that first <code>/</code> was the root of the docker container, not the host machine. People would see this configuration parameter and change it, breaking the system since that user supplied path was on the host, not visable to the mounted volume the docker container knew about.</p>

<p>We fixed this by removing all paths from the config.yaml file, and ensuring our docs were up to date and very clear about what things go in the mounted <code>genconf/</code> directory.</p>

<h5>Legacy Things</h5>

<p>Users who were familiar with our legacy install patterns didn&rsquo;t understand right away that they don&rsquo;t need to ship the software on CM.5, we do that for you by default over SSH. So when they opened the config.yaml file and saw <code>bootstrap_url: file:///opt/tmp_install_dir</code>  their inital response was to change this to the IP where they were going to ship their artifacts from. This of course broke the SSH deployment method since we automatically SCP the artifacts to that file directory on each host, then execute the install script on the host.</p>

<p>We fixed this by being even more clear about that specific parameter in our docs.</p>

<h2>CM.6 - UI Installer</h2>

<h2>Lessons Learned</h2>

<h4>TTYs</h4>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/17/automated-installs-over-ssh-lessons-learned/">How to Deploy Highly Scalable Systems Over SSH</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-17T13:28:26-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>1:28 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Background</h2>

<p>The Secure Shell (SSH) is a well known utility for securely logging into remote hosts. It&rsquo;s also been widely used as a secure remote execution framework. Today, well known tools in the area of configuration management leverage SSH to safely manage state across thousands of hosts. Many systems administrators reach for SSH when they have to automate execution of scripts across distributed hosts, and others use it every day to log into remote systems on cloud platforms.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/01/17/automated-installs-over-ssh-lessons-learned/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/09/05/mantle-encrypted-json-for-the-marathon-api/">Mantle: Encrypted JSON for the Marathon API</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-09-05T13:00:32-07:00'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>5</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>1:00 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img style="float: center;" src="https://dl.dropboxusercontent.com/u/77193293/mantle.png"></p>

<p><a href="https://github.com/malnick/mantle.git">Mantle</a> is a go utility that wraps the POST process to Mesosphere&rsquo;s Marathon API. Before, users had to store JSON with cleartext environment variables for their Docker container configuration. With Mantle, users can encrypt the values for the &ldquo;env&rdquo; parameters passed to Marathon using asynchronous public/private key pairs. Mantle is designed to allow operations or deployment teams to build user-level key pairs, and give those public keys to the users' with the most knowledge of the application&rsquo;s configuration. Those users, can then encode the JSON with Mantle via their public keys and let the deployment team review the JSON and have the final private key to decrypt and deploy to Marathon(s) via Mantle.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/09/05/mantle-encrypted-json-for-the-marathon-api/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/28/elasticsearch-logstash-cli-utility/">Logasaurus: A CLI Utility for Elasticsearch / Logstash</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-08-28T12:19:11-07:00'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>28</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>12:19 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img style="float: center;" src="https://dl.dropboxusercontent.com/u/77193293/logasaurus.png"></p>

<p>Like most operations teams, at SRC:CLR we&rsquo;re offloading our logs to an aggregated log solution. We use the popular ELK (Elasticsearch, Logstash, Kibana). I love this solution but when it comes to simply copying and pasting log data from Kibana things get messy. When our developers need to get data quickly it would be easier to have a CLI utility that can do the same queries than having to open a browser and screen grab from Kibana.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/08/28/elasticsearch-logstash-cli-utility/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/13/version-management-in-soa/">Version Management in SOA</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-08-13T08:47:19-07:00'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>8:47 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Service oriented architectures offer significant increases in agile deployment pipelines. They allow what were traditionally, large, monolithic code bases to be broken down into smaller, more manageable pieces. Instead of diagnosing a single issue that affects the application as a whole, SOA allows developers to troubleshoot smaller, atomic pieces.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/08/13/version-management-in-soa/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/07/31/a-restful-haproxy-service-abstraction/">A Restful Haproxy Service Abstraction</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-07-31T06:05:55-07:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>31</span><span class='date-suffix'>st</span>, <span class='date-year'>2015</span></span> <span class='time'>6:05 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A major hurdle of microservices is visibility into the versions of your deployed infrastructure. At SRC:CLR we have 7 different micro services plus our platform that drive our product. These services are deployed as immutable infrastructure, their IP&rsquo;s and configuration is fluid and changing all the time. During a deployment, we might to a canary update of our services, but having to manually query the <code>/info</code> endpoint across &lsquo;n&rsquo; number of nodes, IP addresses, and dynamic management port assignments is error prone and difficult. In order to gain visibility into the currently running services, we wrote a tool that finds available services by querying our frontend and internal loadbalancers for running services, and then queries those running services to get their running versions and display them in a lightweight frontend.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/07/31/a-restful-haproxy-service-abstraction/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/07/21/weak-dh-ciphers/">Weak Diffe-Helman SSL Ciphers</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-07-21T11:32:12-07:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>21</span><span class='date-suffix'>st</span>, <span class='date-year'>2015</span></span> <span class='time'>11:32 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>We recently scanned our <code>srcclr.com</code> domain via <a href="https://www.ssllabs.com/">Qualsys</a> SSL Labs scanning suite. When we deployed this site in March (a migration from sourceclear.com to srcclr.com) we had an A+ rating.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/07/21/weak-dh-ciphers/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/07/14/static-service-provisioning-sucks/">Static Service Provisioning Sucks</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-07-14T13:05:01-07:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>1:05 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Many tools exist to help automate and orchestrate provisioning servers. Each tool serves a purpose, or is tailored for a specific task. One realization I had not to long ago was that configuration management tools, as a framework, suck at provisioning micro services. I say that at the risk of bringing on the deluge of comments that often accompany such a blunt, over arching statement.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/07/14/static-service-provisioning-sucks/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/06/17/vertically-scaled-infrastructure/">Vertically Scaled Infrastructure</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-06-17T12:48:27-07:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>12:48 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>&ldquo;&hellip;but does is scale?&rdquo;</h2>

<p>When it comes to micro-service architectures that&rsquo;s always the big question. You can maintain a solid agile development process, design a micro service architecture, and implement seamless CI to ensure developers can launch code from their local test environment into Prod but if you can&rsquo;t respond to the increase in demand for your product then who cares? Unusable products, no matter how cool, won&rsquo;t get traffic and your company will suffer.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/06/17/vertically-scaled-infrastructure/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/05/01/automating-spring-boot-micro-service-deployments/">Automating Spring Boot Micro Service Deployments</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-05-01T10:05:30-07:00'><span class='date'><span class='date-month'>May</span> <span class='date-day'>1</span><span class='date-suffix'>st</span>, <span class='date-year'>2015</span></span> <span class='time'>10:05 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Spring is a java framework that has been around for the better part of a decade. Though some argue it&rsquo;s growing long in the tooth, it&rsquo;s still a standard among large enterprise to smaller startup style web applications. Spring boot is Springs answer to next generation, easy-to-implement, spring setup. Spring boot has a host of advantages over it&rsquo;s legacy counterpart, chef among them packaging up your application in jar file format vs. war file format, embedded tomcat, and the primary topic of this post: resource configuration based on config files found in the classpath.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/05/01/automating-spring-boot-micro-service-deployments/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/01/31/building-an-installer-for-the-data-center-operating-system/">Building an Installer for the Data Center Operating System</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/01/17/automated-installs-over-ssh-lessons-learned/">How to Deploy Highly Scalable Systems Over SSH</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/09/05/mantle-encrypted-json-for-the-marathon-api/">Mantle: Encrypted JSON for the Marathon API</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/28/elasticsearch-logstash-cli-utility/">Logasaurus: A CLI Utility for Elasticsearch / Logstash</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/13/version-management-in-soa/">Version Management in SOA</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/malnick">@malnick</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'malnick',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

Included file 'asides/twitter.html' not found in _includes directory
  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Jeff Malnick -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>



<script>
  $(document).ready(function() {  
    var stickyNavTop = $('nav').offset().top;  
      
    var stickyNav = function(){  
      var scrollTop = $(window).scrollTop(); 
      var navHasClassSticky = $('nav').hasClass('sticky');

      if (scrollTop > stickyNavTop && navHasClassSticky) {   
        return true;
      } else if (scrollTop > stickyNavTop) {
        $('nav').hide();
        $('nav').addClass('sticky');
        $('nav').fadeIn('2000');
      } else {  
        $('nav').removeClass('sticky');   
      }  
    };  
      
    stickyNav();  
      
    $(window).scroll(function() {  
      stickyNav();  
    });  
  });  
</script>


</body>
</html>
